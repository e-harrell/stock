---
title: "Stock prices data science project"
author: "Erika Harrell"
date: "2/3/2021"
output: 
  html_document: 
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Summary
### This project compares the high stock prices for 5 stocks: Apple, Netflix, CBS/Viacom, Amazon, and Disney. It took prices from the Yahoo Finance website <https://finance.yahoo.com/> for the dates from September 23, 2020 to November 17, 2020 when the New York Stock Exchange was open. For each stock, it used the high prices for the first 24 dates in the time period to predict the high prices for the next 16 dates.

```{r libraries}
#attach libraries
library(ggplot2)
library(ggthemes)
library(tidyr)
library(quantmod)
library(dplyr)
library(forecast)
```

## Loading Data
### Creating data folder, downloading datasets from Yahoo Finance and loading data into R Studio.

```{r load}
if(!dir.exists("./data")) {dir.create("./data")}
download.file("https://query1.finance.yahoo.com/v7/finance/download/AMZN?period1=1600819200&period2=1605657600&interval=1d&events=history&includeAdjustedClose=true","./data/amazon.csv")

download.file("https://query1.finance.yahoo.com/v7/finance/download/AAPL?period1=1600819200&period2=1605657600&interval=1d&events=history&includeAdjustedClose=truee","./data/apple.csv")

download.file("https://query1.finance.yahoo.com/v7/finance/download/VIAC?period1=1600819200&period2=1605657600&interval=1d&events=history&includeAdjustedClose=true","./data/cbs.csv")

download.file("https://query1.finance.yahoo.com/v7/finance/download/DIS?period1=1600819200&period2=1605657600&interval=1d&events=history&includeAdjustedClose=true","./data/disney.csv")

download.file("https://query1.finance.yahoo.com/v7/finance/download/NFLX?period1=1600819200&period2=1605657600&interval=1d&events=history&includeAdjustedClose=true", "./data/netflix.csv")
amazon<-read.csv("./data/amazon.csv")
apple<-read.csv("./data/apple.csv")
disney<-read.csv("./data/disney.csv")
cbs<-read.csv("./data/cbs.csv")
netflix<-read.csv("./data/netflix.csv")
```

## Data Wrangling
### Look at datasets. Merge into a single dataset and look at merged dataset.

```{r wrangle, echo=FALSE}
#Details of individual data sets
summary(amazon)
str(amazon)
summary(apple)
str(apple)
summary(cbs)
str(cbs)
summary(disney)
str(disney)
summary(netflix)
str(netflix)

#combine into a single data set
data<-cbind(data.frame(Date=as.Date(amazon$Date),
            amazonOpen=round(as.numeric(amazon$Open),2),
            amazonHigh=round(as.numeric(amazon$High),2),
            amazonLow=round(as.numeric(amazon$Low),2),
            amazonClose=round(as.numeric(amazon$Close),2),
            amazonAdj.Close=round(as.numeric(amazon$Adj.Close),2),
            amazonVolume=round(as.numeric(amazon$Volume),0),
            appleOpen=round(as.numeric(apple$Open),2),
            appleHigh=round(as.numeric(apple$High),2),
            appleLow=round(as.numeric(apple$Low),2),
            appleClose=round(as.numeric(apple$Close),2),
            appleAdj.Close=round(as.numeric(apple$Adj.Close),2),
            appleVolume=round(as.numeric(apple$Volume),0),
            cbsOpen=round(as.numeric(cbs$Open),2),
            cbsHigh=round(as.numeric(cbs$High),2),
            cbsLow=round(as.numeric(cbs$Low),2),
            cbsClose=round(as.numeric(cbs$Close),2),
            cbsAdj.Close=round(as.numeric(cbs$Adj.Close),2),
            cbsVolume=round(as.numeric(cbs$Volume),0),
            disneyOpen=round(as.numeric(disney$Open),2),
            disneyHigh=round(as.numeric(disney$High),2),
            disneyLow=round(as.numeric(disney$Low),2),
            disneyClose=round(as.numeric(disney$Close),2),
            disneyAdj.Close=round(as.numeric(disney$Adj.Close),2),
            disneyVolume=round(as.numeric(disney$Volume),0),
            netflixOpen=round(as.numeric(netflix$Open),2),
            netflixHigh=round(as.numeric(netflix$High),2),
            netflixLow=round(as.numeric(netflix$Low),2),
            netflixClose=round(as.numeric(netflix$Close),2),
            netflixyAdj.Close=round(as.numeric(netflix$Adj.Close),2),
            netflixVolume=round(as.numeric(netflix$Volume),0)
            ))
#look at combined dataset
summary(data)
str(data)
```

## Amazon forecasting analysis
### The time chart of the data of the high stock prices for Amazon shows and increase in the high stock prices from September 23 to around October 14. From there, the trend generally in  decreased until around November 2 and a sharp increase on November 3. This preceded a decrease in the high stock price until around November 8. After that decerease, the trend generally remained steady.

```{r amazon}
ggplot(data,aes(Date, amazonHigh, group=1))+
  geom_line(color="darkblue" ,size=2)+
  ggtitle("High stock prices for Amazon Sept 23-Nov 17")
```

### The data was turned into a time series object in R with 40 observations, one for each day that the stock market was open during the time period. A multiplicative decomposition of the time series was conducted. Plotting the trend-cycle and seasonal indices shows that the data have an upward trend during the 1st 2 segments with a downward trend in the 3rd segment followed by a stability in the trend in the 4th segment. It also has seasonal fluctuations, with the data increaseing at the beginning of each segment, reaching apeak in the middle of the segment and decreasing by the end of the segment.The data also has fairly random residuals.

```{r amatime}
#ts function creates time series object
ts1 <- ts(data$amazonHigh,frequency=10)
#decomposition
plot(decompose(ts1,type = "multiplicative"),xlab="segment")
```

### Training and test data sets were created from the time series object with the high stock prices for the first 24 days(60% of the data) being put into the training data while the data for the remaining 16 days (40% of the data) were put into the test data set.

```{r amatrain}
#training & test sets
ts1Train <- window(ts1,start=1,end=3.3)
ts1Test <- window(ts1,start=3.4,end=4.9)
```

### Simple exponential smoothing with multiplicative errors was applied to the training data. This resulted in a smoothing parameter of 0.9999 which means that in the training data, more weight is given to the more recent stock prices in the forecast. Then The plot of the forecasted data along with the test data showed that the forecasted results did fall within the prediction bounds. 

```{r amaforecast}
#exponential smoothing
ets1 <- ets(ts1Train)
ets1
#get predictions and prediction bounds with forecast function
fcast <- forecast(ets1)
plot(fcast); 
lines(ts1Test,col="red")
```

### In terms of accuracy, the root mean squared error was 61 for the training data and 65 for the test data. With a minimum value of  and a maximum value of  ,  .

```{r amaaccuracy}
#get accuracy
#accuracy(forecast,test set)
accuracy(fcast,ts1Test)
```

## Apple forecasting analysis

```{r apple}
ggplot(data,aes(Date, appleHigh, group=1))+
  geom_line(color="darkblue" ,size=2)+
  ggtitle("High stock prices for Apple Sept 23-Nov 17")
```

```{r apptime}
#ts function creates time series object
ts1 <- ts(data$appleHigh,frequency=10)
#decomposition
plot(decompose(ts1),xlab="segment")
```

```{r apptrain}
#training & test sets-have to build sets with consecutive time points
ts1Train <- window(ts1,start=1,end=3.3)
#window function creates test set that starts at time point 2.16
ts1Test <- window(ts1,start=3.4,end=4.9)
```

```{r appforecast}
#exponential smoothing
#fit model that had different types of trends you want to fit
ets1 <- ets(ts1Train)
ets1
#get predictions and prediction bounds with forecast function
fcast <- forecast(ets1)
plot(fcast); 
lines(ts1Test,col="red")
```

```{r appaccuracy}
#get accuracy
#accuracy(forecast,test set)
accuracy(fcast,ts1Test)
```

## CBS/Viacom forecasting analysis

```{r cbs}
ggplot(data,aes(Date, cbsHigh, group=1))+
  geom_line(color="darkblue" ,size=2)+
  ggtitle("High stock prices for CBS/Viacom Sept 23-Nov 17")
```

```{r cbstime}
#ts function creates time series object
ts1 <- ts(data$cbsHigh,frequency=10)
#decomposition
plot(decompose(ts1),xlab="segment")
```


```{r cbstrain}
#training & test sets
ts1Train <- window(ts1,start=1,end=3.3)
ts1Test <- window(ts1,start=3.4,end=4.9)
```

```{r cbsforecast}
#exponential smoothing
#fit model that had different types of trends you want to fit
ets1 <- ets(ts1Train)
ets1
#get predictions and prediction bounds with forecast function
fcast <- forecast(ets1)
plot(fcast); 
lines(ts1Test,col="red")
```

```{r cbsaccuracy}
#get accuracy
#accuracy(forecast,test set)
accuracy(fcast,ts1Test)
```

## Disney forecasting analysis

```{r disney}
ggplot(data,aes(Date, disneyHigh, group=1))+
  geom_line(color="darkblue" ,size=2)+
  ggtitle("High stock prices for Disney Sept 23-Nov 17")
```

```{r disneytime}
#ts function creates time series object
ts1 <- ts(data$disneyHigh,frequency=10)
#decomposition
plot(decompose(ts1),xlab="segment")
```

```{r disneytrain}
#training & test sets
ts1Train <- window(ts1,start=1,end=3.3)
ts1Test <- window(ts1,start=3.4,end=4.9)
```

```{r disforecast}
#exponential smoothing
#fit model that had different types of trends you want to fit
ets1 <- ets(ts1Train)
ets1
#get predictions and prediction bounds with forecast function
fcast <- forecast(ets1)
plot(fcast); 
lines(ts1Test,col="red")
```

```{r disaccuracy}
#get accuracy
#accuracy(forecast,test set)
accuracy(fcast,ts1Test)
```

## Netflix forecasting analysis

```{r netflix}
ggplot(data,aes(Date, netflixHigh, group=1))+
  geom_line(color="darkblue" ,size=2)+
  ggtitle("High stock prices for Netflix Sept 23-Nov 17")
```

```{r nettime}
#ts function creates time series object
ts1 <- ts(data$netflixHigh,frequency=10)
#decomposition
plot(decompose(ts1),xlab="segment")
```

```{r nettrain}
#training & test sets
ts1Train <- window(ts1,start=1,end=3.3)
ts1Test <- window(ts1,start=3.4,end=4.9)
```

```{r netforecast}
#exponential smoothing
#fit model that had different types of trends you want to fit
ets1 <- ets(ts1Train)
ets1
#get predictions and prediction bounds with forecast function
fcast <- forecast(ets1)
plot(fcast); 
lines(ts1Test,col="red")
```

```{r netaccuracy}
#get accuracy
#accuracy(forecast,test set)
accuracy(fcast,ts1Test)
```

